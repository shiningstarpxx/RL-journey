{
  "pure_rl_metrics": {
    "loss": [
      -0.06138227164745331,
      0.01703092649579048,
      0.09421215265989304
    ],
    "reward": [
      -0.09211187779903413,
      0.027563478350639343,
      0.13640238612890243
    ],
    "entropy": [
      0.6929665875434875,
      0.6927728772163391,
      0.6915241622924805
    ]
  },
  "rlhf_metrics": {
    "loss": [
      0.017144933342933655,
      0.05651684619486332,
      -0.04360523886978626
    ],
    "kl_penalty": [
      8.67328948515933e-06,
      1.9225662108510732e-05,
      1.8322602845728396e-05
    ],
    "reward": [
      0.010444234907627106,
      0.07397947460412979,
      -0.06143634587526321
    ]
  },
  "behavior_comparison": {
    "pure_rl_action_dist": "[0.52 0.48]",
    "rlhf_action_dist": "[0.68 0.32]",
    "pure_rl_entropy": "0.6911169",
    "rlhf_entropy": "0.6860136"
  }
}